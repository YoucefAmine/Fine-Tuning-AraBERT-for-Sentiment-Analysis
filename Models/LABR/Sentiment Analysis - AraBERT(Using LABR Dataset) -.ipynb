{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AraBert(SA)_Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0b7c50d30564cffa1d88e417e6f81e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f17d138f5e04cfaa401d75d2a28c63c",
              "IPY_MODEL_3efa519a89cc4a4ab50977e430a8ad05",
              "IPY_MODEL_0d42ef2901bd4c4db253e1c1afa1148c"
            ],
            "layout": "IPY_MODEL_247e86aa79f84332999a5af37c35586a"
          }
        },
        "1f17d138f5e04cfaa401d75d2a28c63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43275755ec843aa859a20957e58085c",
            "placeholder": "​",
            "style": "IPY_MODEL_eedf78bd08f843c48d96968e8c2e131f",
            "value": ""
          }
        },
        "3efa519a89cc4a4ab50977e430a8ad05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2fb853ab8c4e9d990e477c9c0a73c0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_808409806ffc4fadb057e8cfd726ffaa",
            "value": 1
          }
        },
        "0d42ef2901bd4c4db253e1c1afa1148c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ce510a65b54645ae96f2c4c2a3697d",
            "placeholder": "​",
            "style": "IPY_MODEL_ddbff536c0224cd08f67302508a2e888",
            "value": " 320/? [07:44&lt;00:00,  1.37s/it]"
          }
        },
        "247e86aa79f84332999a5af37c35586a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b43275755ec843aa859a20957e58085c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eedf78bd08f843c48d96968e8c2e131f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe2fb853ab8c4e9d990e477c9c0a73c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "808409806ffc4fadb057e8cfd726ffaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5ce510a65b54645ae96f2c4c2a3697d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbff536c0224cd08f67302508a2e888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c40b3c7c2ca94ce189776e3c79bd4346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37e6ed1bfc2841d583ac1804f5a66bc1",
              "IPY_MODEL_fc06940e55284e1ea3e8cb10e2c1921d",
              "IPY_MODEL_1164dabbe8e6469cb8413dc8f980c471"
            ],
            "layout": "IPY_MODEL_8568faac56a942098b353b73305a9737"
          }
        },
        "37e6ed1bfc2841d583ac1804f5a66bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c9cff572c946cfb2b75f7ad2527c1f",
            "placeholder": "​",
            "style": "IPY_MODEL_0b2543d3cbd7463d9b453ddd39a92e33",
            "value": ""
          }
        },
        "fc06940e55284e1ea3e8cb10e2c1921d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d757c6e8c74210afd30f70300cfe5e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1077803fa1704a4bb01828e4a6c0760b",
            "value": 1
          }
        },
        "1164dabbe8e6469cb8413dc8f980c471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835305276fd54a6bb2d9fbca9fdd1aa7",
            "placeholder": "​",
            "style": "IPY_MODEL_3e24cf380c3b44b780036712ef69fb3e",
            "value": " 320/? [08:28&lt;00:00,  1.55s/it]"
          }
        },
        "8568faac56a942098b353b73305a9737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c9cff572c946cfb2b75f7ad2527c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2543d3cbd7463d9b453ddd39a92e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81d757c6e8c74210afd30f70300cfe5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1077803fa1704a4bb01828e4a6c0760b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "835305276fd54a6bb2d9fbca9fdd1aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e24cf380c3b44b780036712ef69fb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d38353721c443f2b66c2574ea8b0cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fd815c51acc4ceeb139d6edaaa796dc",
              "IPY_MODEL_989deb7602974dffae354368dd318fbb",
              "IPY_MODEL_8e4dd91b134e476d825d4ca6d282acab"
            ],
            "layout": "IPY_MODEL_60ec7568744346a4b44c64c572e1650a"
          }
        },
        "1fd815c51acc4ceeb139d6edaaa796dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b9e4c93b60440ba717875698235a27",
            "placeholder": "​",
            "style": "IPY_MODEL_2e8ba307865a46e3a7488aa7027785b6",
            "value": ""
          }
        },
        "989deb7602974dffae354368dd318fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fd3bee219a64573acbcac006fc1c39c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92b2e795fcc94259bdcf57630db3f194",
            "value": 1
          }
        },
        "8e4dd91b134e476d825d4ca6d282acab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3748643c28f4415b14b180c2af2bfa1",
            "placeholder": "​",
            "style": "IPY_MODEL_b0d35bb9c6f14599b55c0cb49ced3a0f",
            "value": " 320/? [09:07&lt;00:00,  1.68s/it]"
          }
        },
        "60ec7568744346a4b44c64c572e1650a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b9e4c93b60440ba717875698235a27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e8ba307865a46e3a7488aa7027785b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fd3bee219a64573acbcac006fc1c39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "92b2e795fcc94259bdcf57630db3f194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3748643c28f4415b14b180c2af2bfa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d35bb9c6f14599b55c0cb49ced3a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a431257ae1a47cd9a05e9e985132d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75064b69e349439286e969d8eb62720e",
              "IPY_MODEL_0cacb1541f344269af578a82c1f3fd97",
              "IPY_MODEL_431469f32f664e7ba18e6d584b0b29ec"
            ],
            "layout": "IPY_MODEL_7dcfc6fe997148149742a17027e1fa16"
          }
        },
        "75064b69e349439286e969d8eb62720e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facdfd8baf07418aa2403e21168e3fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_d1f984b8dbb748f58f0c7ad7af6e6f66",
            "value": ""
          }
        },
        "0cacb1541f344269af578a82c1f3fd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f837d43d2e046e693a0144d52b43c5a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d68817a9201413d9a0f66be0b94c20a",
            "value": 1
          }
        },
        "431469f32f664e7ba18e6d584b0b29ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abad8243935d48c2a321e2d47e77c6b1",
            "placeholder": "​",
            "style": "IPY_MODEL_243cc5e7073448dbbb3bef448f8c79d6",
            "value": " 320/? [09:43&lt;00:00,  1.82s/it]"
          }
        },
        "7dcfc6fe997148149742a17027e1fa16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "facdfd8baf07418aa2403e21168e3fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f984b8dbb748f58f0c7ad7af6e6f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f837d43d2e046e693a0144d52b43c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0d68817a9201413d9a0f66be0b94c20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abad8243935d48c2a321e2d47e77c6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243cc5e7073448dbbb3bef448f8c79d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1889fdc2e4e14df6ba18a7bcdb43875d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eb20352e905428583013a16d794cf77",
              "IPY_MODEL_76dc38e571344f58a410d7a255f101e4",
              "IPY_MODEL_df29f51786f946c5b92d78f08f04b224"
            ],
            "layout": "IPY_MODEL_f1e650a85340472f8e6e14d30f83a92e"
          }
        },
        "5eb20352e905428583013a16d794cf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04be8b29332343d5b72302eaf0342dd3",
            "placeholder": "​",
            "style": "IPY_MODEL_144bb19fd96d492cb7db32d09c882430",
            "value": ""
          }
        },
        "76dc38e571344f58a410d7a255f101e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5003f2c4397e43ca89a889a7b0891525",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e721e7dd6fa44c82bbe167409b3636ba",
            "value": 1
          }
        },
        "df29f51786f946c5b92d78f08f04b224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0de3eb4866da474d80507af29f63fbcf",
            "placeholder": "​",
            "style": "IPY_MODEL_7077374dfa494347874ce61f313100e2",
            "value": " 320/? [10:29&lt;00:00,  1.90s/it]"
          }
        },
        "f1e650a85340472f8e6e14d30f83a92e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04be8b29332343d5b72302eaf0342dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144bb19fd96d492cb7db32d09c882430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5003f2c4397e43ca89a889a7b0891525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e721e7dd6fa44c82bbe167409b3636ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0de3eb4866da474d80507af29f63fbcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7077374dfa494347874ce61f313100e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis - AraBERT(Using LABR Dataset) -**"
      ],
      "metadata": {
        "id": "jFHm4_-I6W8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Dependencies installation**"
      ],
      "metadata": {
        "id": "WqRFL-V560Es"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm7cZyJ1qO9I",
        "outputId": "652f660d-3f36-4779-f4ef-1324c30f3851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Sat May 14 14:46:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    34W /  70W |  11132MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "U9nII7DsWJ7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a302242-56f0-4ff7-efeb-a6ad98a304e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.12.2\n",
        "!pip install farasapy==0.0.14\n",
        "!pip install pyarabic==0.6.14\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install emoji==1.6.1\n",
        "!pip install sentencepiece==0.1.96"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz0UvYXwrDvR",
        "outputId": "10c5b6cb-39f2-4156-c528-2999d7e14b94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.12.2\n",
            "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (4.64.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (21.3)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.2) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.12.2) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.12.2) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.12.2) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.12.2) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=21a2d3450a70afdc00d99768f1701ecd74929009031f605c3134e56bcfb2c79b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.12.2\n",
            "Collecting farasapy==0.0.14\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy==0.0.14) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy==0.0.14) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy==0.0.14) (2021.10.8)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n",
            "Collecting pyarabic==0.6.14\n",
            "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic==0.6.14) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.14\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 564, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 564 (delta 25), reused 22 (delta 22), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (564/564), 9.11 MiB | 32.16 MiB/s, done.\n",
            "Resolving deltas: 100% (326/326), done.\n",
            "Collecting emoji==1.6.1\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 7.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169313 sha256=44978cca0dbc09720cd3a37dd089fa6c39448f804d8ef550f21b83340b7c9e76\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n",
            "Collecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 6.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mohamedadaly/LABR\n",
        "!git clone https://github.com/elnagara/HARD-Arabic-Dataset\n",
        "!wget http://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip\n",
        "!unzip ArSAS.zip\n",
        "!unzip '/content/HARD-Arabic-Dataset/data/balanced-reviews.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAg7owv5rWX0",
        "outputId": "228843bd-ac1a-41c0-97c9-9aaacc584a34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LABR'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n",
            "Cloning into 'HARD-Arabic-Dataset'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Total 100 (delta 0), reused 0 (delta 0), pack-reused 100\u001b[K\n",
            "Receiving objects: 100% (100/100), 116.36 MiB | 30.71 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "--2022-05-14 12:39:18--  http://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip\n",
            "Resolving homepages.inf.ed.ac.uk (homepages.inf.ed.ac.uk)... 129.215.32.113\n",
            "Connecting to homepages.inf.ed.ac.uk (homepages.inf.ed.ac.uk)|129.215.32.113|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip [following]\n",
            "--2022-05-14 12:39:18--  https://homepages.inf.ed.ac.uk/wmagdy/Resources/ArSAS.zip\n",
            "Connecting to homepages.inf.ed.ac.uk (homepages.inf.ed.ac.uk)|129.215.32.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1905723 (1.8M) [application/zip]\n",
            "Saving to: ‘ArSAS.zip’\n",
            "\n",
            "ArSAS.zip           100%[===================>]   1.82M  1.82MB/s    in 1.0s    \n",
            "\n",
            "2022-05-14 12:39:20 (1.82 MB/s) - ‘ArSAS.zip’ saved [1905723/1905723]\n",
            "\n",
            "Archive:  ArSAS.zip\n",
            "  inflating: ArSAS..txt              \n",
            "Archive:  /content/HARD-Arabic-Dataset/data/balanced-reviews.zip\n",
            "  inflating: balanced-reviews.txt    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Datasets preparation**"
      ],
      "metadata": {
        "id": "Fzzbt8107d2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "JuwBjnbVrpB0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        train: List[pd.DataFrame],\n",
        "        test: List[pd.DataFrame],\n",
        "        label_list: List[str],\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "        self.label_list = label_list"
      ],
      "metadata": {
        "id": "EhjX4VTjr1m7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_datasets= []\n",
        "DATA_COLUMN = \"text\"\n",
        "LABEL_COLUMN = \"label\""
      ],
      "metadata": {
        "id": "OY3PoylnsIKK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_HARD = pd.read_csv(\"/content/balanced-reviews.txt\", sep=\"\\t\", header=0,encoding='utf-16')\n",
        "\n",
        "df_HARD = df_HARD[[\"review\",\"rating\"]]  # we are interested in rating and review only\n",
        "df_HARD.columns = [DATA_COLUMN, LABEL_COLUMN]\n",
        "print(df_HARD[LABEL_COLUMN].value_counts())\n",
        "# code rating as +ve if > 3, -ve if less, no 3s in dataset\n",
        "\n",
        "hard_map = {\n",
        "    5: 'POS',\n",
        "    4: 'POS',\n",
        "    2: 'NEG',\n",
        "    1: 'NEG'\n",
        "}\n",
        "\n",
        "df_HARD[LABEL_COLUMN] = df_HARD[LABEL_COLUMN].apply(lambda x: hard_map[x])\n",
        "train_HARD, test_HARD = train_test_split(df_HARD, test_size=0.2, random_state=42)\n",
        "label_list_HARD = ['NEG', 'POS']\n",
        "\n",
        "data_Hard = CustomDataset(\"HARD\", train_HARD, test_HARD, label_list_HARD)\n",
        "all_datasets.append(data_Hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "requQgOKMi8K",
        "outputId": "f6e87926-b74a-4640-d7bc-dc0660e9d085"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2    38467\n",
            "4    26450\n",
            "5    26399\n",
            "1    14382\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%writefile labr.py\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Mar 10 16:27:03 2013\n",
        "\n",
        "@author: Mohamed Aly <mohamed@mohamedaly.info>\n",
        "\"\"\"\n",
        "\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "class LABR:\n",
        "    def __init__(self):\n",
        "        self.REVIEWS_PATH = \"LABR/data/\"\n",
        "        self.RAW_REVIEWS_FILE = \"raw_reviews.tsv\"\n",
        "        self.DELETED_REVIEWS_FILE = \"deleted_reviews.tsv\"\n",
        "        self.CLEAN_REVIEWS_FILE = \"reviews.tsv\"\n",
        "\n",
        "    # Copied from the PyArabic package.\n",
        "    def arabicrange(self):\n",
        "        \"\"\"return a list of arabic characteres .\n",
        "        Return a list of characteres between \\u060c to \\u0652\n",
        "        @return: list of arabic characteres.\n",
        "        @rtype: unicode;\n",
        "        \"\"\"\n",
        "        mylist=[];\n",
        "        for i in range(0x0600, 0x00653):\n",
        "            try :\n",
        "                mylist.append(unichr(i));\n",
        "            except ValueError:\n",
        "                pass;\n",
        "        return mylist;\n",
        "\n",
        "    # cleans a single review\n",
        "    def clean_raw_review(self, body):\n",
        "         # patterns to remove first\n",
        "        pat = [\\\n",
        "            (u'http[s]?://[a-zA-Z0-9_\\-./~\\?=%&]+', u''),               # remove links\n",
        "            (u'www[a-zA-Z0-9_\\-?=%&/.~]+', u''),\n",
        "#            u'\\n+': u' ',                     # remove newlines\n",
        "            (u'<br />', u' '),                  # remove html line breaks\n",
        "            (u'</?[^>]+>', u' '),              # remove html markup\n",
        "#            u'http': u'',\n",
        "            (u'[a-zA-Z]+\\.org', u''),\n",
        "            (u'[a-zA-Z]+\\.com', u''),\n",
        "            (u'://', u''),\n",
        "            (u'&[^;]+;', u' '),\n",
        "            (u':D', u':)'),\n",
        "#            (u'[0-9/]+', u''),\n",
        "#            u'[a-zA-Z.]+': u'',\n",
        "#            u'[^0-9' + u''.join(self.arabicrange()) + \\\n",
        "#                u\"!.,;:$%&*%'#(){}~`\\[\\]/\\\\\\\\\\\"\" + \\\n",
        "#                u'\\s^><\\-_\\u201D\\u00AB=\\u2026]+': u'',          # remove latin characters\n",
        "            (u'\\s+', u' '),                     # remove spaces\n",
        "            (u'\\.+', u'.'),                     # multiple dots\n",
        "            (u'[\\u201C\\u201D]', u'\"'),          #“\n",
        "            (u'[\\u2665\\u2764]', u''),           # heart symbol\n",
        "            (u'[\\u00BB\\u00AB]', u'\"'),\n",
        "            (u'\\u2013', u'-'),                # dash\n",
        "        ]\n",
        "\n",
        "        # patterns that disqualify a review\n",
        "        remove_if_there = [\\\n",
        "            (u'[^0-9' + u''.join(self.arabicrange()) + \\\n",
        "                u\"!.,;:$%&*%'#(){}~`\\[\\]/\\\\\\\\\\\"\" + \\\n",
        "                u'\\s\\^><\\-_\\u201D\\u00AB=\\u2026+|' + \\\n",
        "                u'\\u0660-\\u066D\\u201C\\u201D' + \\\n",
        "                u'\\ufefb\\ufef7\\ufef5\\ufef9]+', u''),                   # non arabic characters\n",
        "        ]\n",
        "\n",
        "        # patterns that disqualify if empty after removing\n",
        "        remove_if_empty_after = [\\\n",
        "            (u'[0-9a-zA-Z\\-_]', u' '),             #alpha-numeric\n",
        "            (u'[0-9' + u\".,!;:$%&*%'#(){}~`\\[\\]/\\\\\\\\\\\"\" + \\\n",
        "                u'\\s\\^><`\\-=_+]+', u''),                  # remove just punctuation\n",
        "            (u'\\s+', u' '),                     # remove spaces\n",
        "        ]\n",
        "\n",
        "        # remove again\n",
        "        # patterns to remove\n",
        "        pat2 = [\\\n",
        "#            u'[^0-9' + u''.join(self.arabicrange()) + \\\n",
        "#                u\"!.,;:$%&*%'#(){}~`\\[\\]/\\\\\\\\\\\"\" + \\\n",
        "#                u'\\s^><\\-_\\u201D\\u00AB=\\u2026]+': u'',          # remove latin characters\n",
        "        ]\n",
        "\n",
        "        skip = False\n",
        "\n",
        "        # if empty body, skip\n",
        "        if body == u'': skip = True\n",
        "\n",
        "        # do some subsitutions\n",
        "        for k,v in pat:\n",
        "            body = re.sub(k, v, body)\n",
        "\n",
        "        # remove if exist\n",
        "        for k,v in remove_if_there:\n",
        "            if re.search(k, body):\n",
        "                skip = True\n",
        "\n",
        "        # remove if empty after replacing\n",
        "        for k,v in remove_if_empty_after:\n",
        "            temp = re.sub(k, v, body)\n",
        "            if temp == u\" \" or temp == u\"\":\n",
        "                skip = True\n",
        "\n",
        "        # do some more subsitutions\n",
        "        if not skip:\n",
        "            for k,v in pat2:\n",
        "                body = re.sub(k, v, body)\n",
        "\n",
        "        # if empty string, skip\n",
        "        if body == u'' or body == u' ':\n",
        "            skip = True\n",
        "\n",
        "        if not skip:\n",
        "            return body\n",
        "        else:\n",
        "            return u\"\"\n",
        "\n",
        "    # Read raw reviews from file and clean and write into clean_reviews\n",
        "    def clean_raw_reviews(self):\n",
        "        # input file\n",
        "        in_file = codecs.open(self.REVIEWS_PATH + self.RAW_REVIEWS_FILE,\n",
        "                              'r', encoding=\"utf-8\")\n",
        "        reviews = in_file.readlines()\n",
        "\n",
        "        # Output file: rating<tab>content\n",
        "        out_file = open(self.REVIEWS_PATH + self.CLEAN_REVIEWS_FILE,\n",
        "                        'w', buffering = 100)\n",
        "        deleted_file = open(self.REVIEWS_PATH + self.DELETED_REVIEWS_FILE,\n",
        "                            'w', buffering = 100)\n",
        "\n",
        "        counter = 1\n",
        "        for i in xrange(0, len(reviews)):\n",
        "            review = reviews[i]\n",
        "            skip = False\n",
        "\n",
        "#           # If line starts with #, then skip\n",
        "#            if review[0] == u\"#\": continue\n",
        "\n",
        "            # split by <tab>\n",
        "            parts = review.split(u\"\\t\")\n",
        "\n",
        "            # rating is first part and body is last part\n",
        "            rating = parts[0]\n",
        "            review_id = parts[1]\n",
        "            user_id = parts[2]\n",
        "            book_id = parts[3]\n",
        "            body = parts[4].strip()\n",
        "\n",
        "            # clean body\n",
        "            body = self.clean_raw_review(body)\n",
        "            if body == u\"\": skip = True\n",
        "\n",
        "            if i % 5000 == 0:\n",
        "                print(\"review %d:\" % (i))\n",
        "\n",
        "            # write output\n",
        "            line = u\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (rating, review_id, user_id,\n",
        "                                              book_id, body)\n",
        "            if not skip:\n",
        "                out_file.write(line.encode('utf-8'))\n",
        "                counter += 1\n",
        "            else:\n",
        "                deleted_file.write(line.encode('utf-8'))\n",
        "\n",
        "    # Read the reviews file. Returns a tuple containing these lists:\n",
        "    #   rating: the rating 1 -> 5\n",
        "    #   review_id: the id of the review\n",
        "    #   user_id: the id of the user\n",
        "    #   book_id: the id of the book\n",
        "    #   body: the text of the review\n",
        "    def read_review_file(self, file_name):\n",
        "        reviews = codecs.open(file_name, 'r', 'utf-8').readlines()\n",
        "\n",
        "        # remove comment lines and newlines\n",
        "        reviews = [r.strip() for r in reviews if r[0] != u'#']\n",
        "\n",
        "        # parse\n",
        "        rating = list()\n",
        "        review_id = list()\n",
        "        user_id = list()\n",
        "        book_id = list()\n",
        "        body = list()\n",
        "        for review in reviews:\n",
        "            # split by <tab>\n",
        "            parts = review.split(u\"\\t\")\n",
        "\n",
        "            # rating is first part and body is last part\n",
        "            rating.append(int(parts[0]))\n",
        "            review_id.append(parts[1])\n",
        "            user_id.append(parts[2])\n",
        "            book_id.append(parts[3])\n",
        "            if len(parts) > 4:\n",
        "                body.append(parts[4])\n",
        "            else:\n",
        "                body.append(u\"\")\n",
        "\n",
        "        return (rating, review_id, user_id, book_id, body)\n",
        "\n",
        "    # Writes reviews to a file\n",
        "    def write_review_file(self, file_name, rating, review_id, user_id,\n",
        "                          book_id, body):\n",
        "\n",
        "        lines = list()\n",
        "        # loop\n",
        "        for i in xrange(len(rating)):\n",
        "            line = u\"%s\\t%s\\t%s\\t%s\\t%s\\n\" % (rating[i], review_id[i],\n",
        "                                              user_id[i], book_id[i],\n",
        "                                              body[i])\n",
        "            lines.append(line)\n",
        "\n",
        "        open(file_name, 'w').write(u''.join(lines).encode('utf-8'))\n",
        "\n",
        "    def read_clean_reviews(self):\n",
        "        return self.read_review_file(self.REVIEWS_PATH +\n",
        "                                     self.CLEAN_REVIEWS_FILE)\n",
        "\n",
        "    def read_raw_reviews(self):\n",
        "        return self.read_review_file(self.REVIEWS_PATH + self.RAW_REVIEWS_FILE)\n",
        "\n",
        "    # Splits the dataset into a training/test sets in the setting of using 5\n",
        "    # classes (predicting the rating value from 1 to 5)\n",
        "    def split_train_test_5class(self, rating, percent_test,\n",
        "                                balanced = \"unbalanced\"):\n",
        "        np.random.seed(1234)\n",
        "\n",
        "        num_reviews = len(rating)\n",
        "        review_ids = np.arange(0, num_reviews)\n",
        "\n",
        "        if balanced == \"unbalanced\":\n",
        "            ntest = np.floor(num_reviews * percent_test)\n",
        "            np.random.shuffle(review_ids)\n",
        "\n",
        "            test_ids = review_ids[:ntest]\n",
        "            train_ids = review_ids[ntest:]\n",
        "\n",
        "        elif balanced == \"balanced\":\n",
        "            (sizes, bins) = np.histogram(rating, [1, 2, 3, 4, 5, 6])\n",
        "            min_size = np.min(sizes)\n",
        "            print(min_size)\n",
        "\n",
        "            # sample review ids equally among classes\n",
        "            test_ids = np.zeros((0,), dtype=\"int32\")\n",
        "            train_ids = np.zeros((0,), dtype=\"int32\")\n",
        "            rating = np.array(rating)\n",
        "            ntest = np.floor(min_size * percent_test)\n",
        "            for c in range(1, 6):\n",
        "                cids = review_ids[np.nonzero(rating == c)]\n",
        "                np.random.shuffle(cids)\n",
        "\n",
        "                test_ids = np.r_[test_ids, cids[:ntest]]\n",
        "                train_ids = np.r_[train_ids, cids[ntest:min_size]]\n",
        "\n",
        "        train_file = self.REVIEWS_PATH + \"5class-\" + balanced+ \"-train.txt\"\n",
        "        test_file = self.REVIEWS_PATH + \"5class-\" + balanced+ \"-test.txt\"\n",
        "\n",
        "        open(train_file, 'w').write('\\n'.join(map(str, train_ids)))\n",
        "        open(test_file, 'w').write('\\n'.join(map(str, test_ids)))\n",
        "\n",
        "        return (train_ids, test_ids)\n",
        "\n",
        "    # Splits the dataset into a training/test sets in the setting of using 2\n",
        "    # classes (predicting the polarity of the review where ratings 1 & 2\n",
        "    # are considered negative, ratings 4 & 5 are positive, and rating 3 is\n",
        "    # ignored)\n",
        "    def split_train_test_2class(self, rating, percent_test,\n",
        "                                balanced = \"unbalanced\"):\n",
        "        np.random.seed(1234)\n",
        "\n",
        "        rating = np.array(rating, dtype='int32')\n",
        "        # length\n",
        "        num_reviews = len(rating)\n",
        "        review_ids = np.arange(0, num_reviews)\n",
        "\n",
        "        # convert to binary, with ratings [1, 2] --> neg and [4, 5] --> pos\n",
        "        rating[rating == 2] = 1\n",
        "        rating[rating == 4] = 5\n",
        "\n",
        "        ids = (rating == 1) + (rating == 5)\n",
        "        review_ids = review_ids[ids]\n",
        "        rating = rating[ids]\n",
        "        rating[rating == 1] = 0\n",
        "        rating[rating == 5] = 1\n",
        "\n",
        "        # get length after filtering\n",
        "        num_reviews = rating.shape[0]\n",
        "\n",
        "        if balanced == \"unbalanced\":\n",
        "            ntest = np.floor(num_reviews * percent_test)\n",
        "            np.random.shuffle(review_ids)\n",
        "\n",
        "            test_ids = review_ids[:ntest]\n",
        "            train_ids = review_ids[ntest:]\n",
        "\n",
        "        elif balanced == \"balanced\":\n",
        "            (sizes, bins) = np.histogram(rating, [0, 1, 2])\n",
        "            min_size = np.min(sizes)\n",
        "            print(min_size)\n",
        "\n",
        "            # sample review ids equally among classes\n",
        "            test_ids = np.zeros((0,), dtype=\"int32\")\n",
        "            train_ids = np.zeros((0,), dtype=\"int32\")\n",
        "            rating = np.array(rating)\n",
        "            ntest = np.floor(min_size * percent_test)\n",
        "            for c in [0, 1]:\n",
        "                cids = review_ids[np.nonzero(rating == c)]\n",
        "                np.random.shuffle(cids)\n",
        "\n",
        "                test_ids = np.r_[test_ids, cids[:ntest]]\n",
        "                train_ids = np.r_[train_ids, cids[ntest:min_size]]\n",
        "\n",
        "        train_file = self.REVIEWS_PATH + \"2class-\" + balanced+ \"-train.txt\"\n",
        "        test_file = self.REVIEWS_PATH + \"2class-\" + balanced+ \"-test.txt\"\n",
        "\n",
        "        open(train_file, 'w').write('\\n'.join(map(str, train_ids)))\n",
        "        open(test_file, 'w').write('\\n'.join(map(str, test_ids)))\n",
        "\n",
        "        return (train_ids, test_ids)\n",
        "\n",
        "    # Reads a training or test file. The file contains the indices of the\n",
        "    # reviews from the clean reviews file.\n",
        "    def read_train_test_file(self, file_name):\n",
        "        ins = open(file_name).readlines()\n",
        "        ins = [int(i.strip()) for i in ins]\n",
        "\n",
        "        return ins\n",
        "\n",
        "    # A helpter function.\n",
        "    def set_binary_klass(self, ar):\n",
        "        ar[(ar == 1) + (ar == 2)] = 0\n",
        "        ar[(ar == 4) + (ar == 5)] = 1\n",
        "\n",
        "    # Returns (train_x, train_y, test_x, test_y)\n",
        "    # where x is the review body and y is the rating (1->5 or 0->1)\n",
        "    def get_train_test(self, klass = \"2\", balanced = \"balanced\"):\n",
        "        (rating, a, b, c, body) = self.read_clean_reviews()\n",
        "        rating = np.array(rating)\n",
        "        body = pd.Series(body)\n",
        "\n",
        "        train_file = (self.REVIEWS_PATH + klass + \"class-\" +\n",
        "            balanced+ \"-train.txt\")\n",
        "        test_file = (self.REVIEWS_PATH + klass + \"class-\" +\n",
        "            balanced+ \"-test.txt\")\n",
        "\n",
        "        train_ids = self.read_train_test_file(train_file)\n",
        "        test_ids = self.read_train_test_file(test_file)\n",
        "\n",
        "        train_y = rating[train_ids]\n",
        "        test_y = rating[test_ids]\n",
        "        train_x = body[train_ids]\n",
        "        test_x = body[test_ids]\n",
        "\n",
        "        if klass == \"2\":\n",
        "            self.set_binary_klass(train_y)\n",
        "            self.set_binary_klass(test_y)\n",
        "\n",
        "        return (train_x, train_y, test_x, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eomV4qhWNA2m",
        "outputId": "926a99de-6d1d-409c-9753-904f943c3a82"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing labr.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from labr import LABR\n",
        "\n",
        "labr_helper = LABR()\n",
        "\n",
        "(d_train, y_train, d_test, y_test) = labr_helper.get_train_test(\n",
        "    klass=\"2\", balanced=\"unbalanced\"\n",
        ")\n",
        "\n",
        "train_LABR_B_U = pd.DataFrame({DATA_COLUMN: d_train, LABEL_COLUMN: y_train})\n",
        "test_LABR_B_U = pd.DataFrame({DATA_COLUMN: d_test, LABEL_COLUMN: y_test})\n",
        "\n",
        "train_LABR_B_U[LABEL_COLUMN] = train_LABR_B_U[LABEL_COLUMN].apply(lambda x: 'NEG' if (x == 0) else 'POS')\n",
        "test_LABR_B_U[LABEL_COLUMN] = test_LABR_B_U[LABEL_COLUMN].apply(lambda x: 'NEG' if (x == 0) else 'POS')\n",
        "\n",
        "print(train_LABR_B_U[LABEL_COLUMN].value_counts() + test_LABR_B_U[LABEL_COLUMN].value_counts())\n",
        "label_list_LABR_B_U = list(test_LABR_B_U[LABEL_COLUMN].unique())\n",
        "\n",
        "data_LABR_B_U = CustomDataset(\n",
        "    \"LABR-UN-Binary\", train_LABR_B_U, test_LABR_B_U, label_list_LABR_B_U\n",
        ")\n",
        "all_datasets.append(data_LABR_B_U)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHt5EFypNDFc",
        "outputId": "f887a8ab-493c-4c3a-e3a5-9613ac8b4a20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS    42832\n",
            "NEG     8224\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ArSAS = pd.read_csv(\"/content/ArSAS..txt\", sep=\"\\t\",encoding='utf-8')\n",
        "df_ArSAS = df_ArSAS[[\"Tweet_text\",\"Sentiment_label\"]]  \n",
        "df_ArSAS.columns = [DATA_COLUMN, LABEL_COLUMN]\n",
        "print(\"Total length: \", len(df_ArSAS))\n",
        "print(df_ArSAS[LABEL_COLUMN].value_counts())\n",
        "\n",
        "label_list_ArSAS = list(df_ArSAS[LABEL_COLUMN].unique())\n",
        "print(label_list_ArSAS)\n",
        "\n",
        "train_ArSAS, test_ArSAS = train_test_split(df_ArSAS, test_size=0.2, random_state=42)\n",
        "print(\"Training length: \", len(train_ArSAS))\n",
        "print(\"Testing length: \", len(test_ArSAS))\n",
        "data_ArSAS = CustomDataset(\"ArSAS\", train_ArSAS, test_ArSAS, label_list_ArSAS)\n",
        "all_datasets.append(data_ArSAS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UKlWhmIsbZH",
        "outputId": "be8b53eb-8a90-461a-a282-b3d3b0428284"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total length:  19897\n",
            "Negative    7384\n",
            "Neutral     6894\n",
            "Positive    4400\n",
            "Mixed       1219\n",
            "Name: label, dtype: int64\n",
            "['Positive', 'Negative', 'Neutral', 'Mixed']\n",
            "Training length:  15917\n",
            "Testing length:  3980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Training procedure**"
      ],
      "metadata": {
        "id": "qzP_ZPSt8HyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             confusion_matrix, f1_score, precision_score,\n",
        "                             recall_score)\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertTokenizer, Trainer,\n",
        "                          TrainingArguments)\n",
        "from transformers.data.processors.utils import InputFeatures"
      ],
      "metadata": {
        "id": "1IF7-yzwsnA4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in all_datasets:\n",
        "  print(x.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "708nIXCvssYU",
        "outputId": "40d4b488-5e53-4c6c-fac6-dd3f6e2a1cae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HARD\n",
            "LABR-UN-Binary\n",
            "ArSAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'LABR-UN-Binary'\n",
        "model_name = 'aubmindlab/bert-base-arabertv02-twitter' "
      ],
      "metadata": {
        "id": "h98alLNpsxM_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in all_datasets:\n",
        "  if d.name==dataset_name:\n",
        "    selected_dataset = copy.deepcopy(d)\n",
        "    print('Dataset found')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk2aSd8vs-LF",
        "outputId": "ffb84650-4b5b-4809-a287-e52e700cd44e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_prep = ArabertPreprocessor(model_name)\n",
        "\n",
        "selected_dataset.train[DATA_COLUMN] = selected_dataset.train[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))\n",
        "selected_dataset.test[DATA_COLUMN] = selected_dataset.test[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))  "
      ],
      "metadata": {
        "id": "NDuiXmiDtDuP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(selected_dataset.train[DATA_COLUMN][0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGT8zUhItXjh",
        "outputId": "0558ab11-413f-42fb-f722-269dd27a7fce"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['رواية ضعيفة جدا ، استخدام الفاظ سوقية بدون داعي ، ايقاع غير مفهوم لا يتسم بالسرعة بالرغم من محاولات الكاتب … قراءة هذه الرواية هو نوع من التعذيب البطئ',\n",
              " 'السبب اللي خلاني اقراها هو كثرة الناس اللي قرتها حسيت كل ما ادخل صفحات و كذا القاها وحماس البعض لها ، خلصتها بيومين و احمد ربي انها كانت نسخه اليكترونيه لان تقييمي لها نجمتين للاسلوب الادبي الجميل فيها ، الرواية عاطفييه جمان تحب عزيز التقت فيه بمقهى ، تصوير جمان بانها هششه جدا ما عجبني و ماتتعلم من اخطائها ابدا ! و احس المبادئ شي صعب الواحد يتخلى عنها لكن بالرواية أظهرت بشكل عادي جدا ، عزيز جذااب بس احممق بشكل كبير و متعجرف جدا ، لكن المشكلة الكبرى و الزبده هي بان جمان وقعت في حبه و هنا يتجسد المثل الحب عذاب * الله لا يعذبنا * و جمان حبته و تعلقت فيه بشكل كبير ، عموما الرواية كقصه عادية و مباالغ فيها و و مصوره انه الاشياء و العلاقات اللي فيها عاديه جدا و هي اككبر خطا ! اكثر شي عجبني الاسلوب الادبي و مقتطفات كثير حلوه . اللي يقراها لازم يكون عااقل جدا لانها تخلي الغلط عادي !',\n",
              " 'قرأت الزهايمر بشغف وعشقت فلسفة غازي كثيرا فلسفته ف الحياة . الإنسان . الماضي والحاضر والمستقبل ايضا . الهروب من والى والذكريات ومحاولة استرجاعها عبثا . محاولة انسان ذو ذاكرة ضيعفة ف تذكر طفولته مراهقته . بدايات حبه ! وكيف للإنسان ان يعيش دون ماض دون ذكريات ؟ ! كيف للإنسان ان ينسى اسم حبيبته ؟ ! حبيبته الأولى ؟ ! اول حب ! اول ذكرى ! اول عناق ! ! واجمل قبلة ؟ ! محاولات مريض الزهايمر كانت بائسة ف تذكر ماضيه وذكرياته . يشعر بالضعف الألم وهم يهم بالتذكر كل مرة ثم يفشل ! ! يتألم ويعاني وهو يفقد ذاكراته شيئا فشئا يفقد ذكرياته ، ماضيه ، ليبقى متخبطا دون هوية ! ! جميلة هي الزهايمر قصيرة جدا ماتعة وشائقة لولا اني خالفته بمسألة الإختلاط عندما قال ولم يكن الإختلاط طامة كبرى . ) هنا انكر الكاتب تحريم الإختلاط ويجزم انه لم يكن محرما عند اسلافنا العرب ف حين ان الإختلاط محرم بالكتاب والسنة ، انا هنا لا افتي ولكني اختلف معه ف هذه المسألة . النقطة الثانية التي لم تروقني ف القصة تناول الجسد وجرأته بالطرح وبالنسبة لي امقت ان تكون الرواية فيها شيئا من الغرائز والجسد والحديث عن الشهوة بإسهاب . ف النهاية الكتاب جدا مشوق وقصير وخفيف يمكنك انهائه ف ساعتين',\n",
              " 'مبدع لو فيه اكتر من 5 نجوم كنت اديتها . اسلوب سلس و تعاقب احداث مايخليش الواحد يمل او يقول اكملها بكرة ولولا ان كان عندي امتحان انا كنت خلصتها مرة واحدة بس حصل خير و خلصت على مرتين : ) )',\n",
              " 'محاولة غير موفقة من الأديب لعرض مآسي القطر المصري في أواخر أيام الملكية المتهالكة ، كان الكتاب خالي من التشويق يرسم لوحات ميته لصور من التفاوت الاجتماعي و الفقر المنتشر في مصر في تلك الايام',\n",
              " 'كما أن حريتهم في أن يمنحوا . حريتي في أن أمنع : )',\n",
              " 'رواية زبالة',\n",
              " 'باختصار , لم أشعر بالملل في حياتي مثلما شعرت وأنا أقرأ هذه الرواية',\n",
              " 'عندما تحاكى الكلمات المشاعر فى رقتها : )',\n",
              " 'رسالة على المفعمة ب يأس و كآبة']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QhZVZNVthQT",
        "outputId": "40799452-0af6-4310-af67-06cb26951bc0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in selected_dataset.train[DATA_COLUMN].to_list()],bins=range(0,128,2))\n",
        "plt.show()\n",
        "\n",
        "print(\"Testing Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in selected_dataset.test[DATA_COLUMN].to_list()],bins=range(0,128,2))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "UHwwsRCvtlP-",
        "outputId": "3c2967c6-46e1-4f11-826b-c247899d6597"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 128"
      ],
      "metadata": {
        "id": "lwmEQUArtrwD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Truncated training sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in selected_dataset.test[DATA_COLUMN].to_list()]))\n",
        "\n",
        "print(\"Truncated testing sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in selected_dataset.test[DATA_COLUMN].to_list()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wZtujortvhs",
        "outputId": "4fba500a-d371-408a-fd1e-80f8aea4788a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncated training sequences:  1460\n",
            "Truncated testing sequences:  1460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(ClassificationDataset).__init__()\n",
        "      \n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "      \n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "        \n",
        "      inputs = self.tokenizer(\n",
        "          text,\n",
        "          max_length=self.max_len,\n",
        "          padding='max_length',\n",
        "          truncation=True\n",
        "      )      \n",
        "      return InputFeatures(**inputs,label=self.label_map[self.target[item]])"
      ],
      "metadata": {
        "id": "XRH2eejstz8y"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = { v:index for index, v in enumerate(selected_dataset.label_list) }\n",
        "print(label_map)\n",
        "\n",
        "train_dataset = ClassificationDataset(\n",
        "    selected_dataset.train[DATA_COLUMN].to_list(),\n",
        "    selected_dataset.train[LABEL_COLUMN].to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )\n",
        "test_dataset = ClassificationDataset(\n",
        "    selected_dataset.test[DATA_COLUMN].to_list(),\n",
        "    selected_dataset.test[LABEL_COLUMN].to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YKnNTLt9VY",
        "outputId": "39451652-6d68-45bd-d639-f63d9ddad6ad"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NEG': 0, 'POS': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(train_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tZ89-vWuCVL",
        "outputId": "61b5cc71-a0c3-40c2-8434-58cb02516e9a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InputFeatures(input_ids=[2, 7609, 13277, 1626, 103, 1898, 5886, 231, 55500, 3340, 27230, 103, 36776, 650, 5909, 391, 21187, 27981, 6262, 306, 5762, 4376, 176, 6442, 450, 6357, 583, 2132, 306, 12340, 1467, 233, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
      ],
      "metadata": {
        "id": "0PeG1fzYuHAo"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  #print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  #macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  #macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {       \n",
        "      'macro_f1' : macro_f1,\n",
        "      'accuracy': acc\n",
        "  }"
      ],
      "metadata": {
        "id": "58MW1GJ-uLdw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic=True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "wS_1iE1tuRwV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Regular Training**"
      ],
      "metadata": {
        "id": "3mf3Of0J8lGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments( \n",
        "    output_dir= \"./train\",    \n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 25\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ],
      "metadata": {
        "id": "ng1QXV4iuXp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c82487-14c0-4981-939d-a751c06c326c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrUNQh96udaD",
        "outputId": "c37949c6-9dd0-45d4-c698-701695194620"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1109ac490c1eb90f74960e17c00032f27ea3c4be159567d7ed5d2b5908f9855c.01294502d101541d98086466d32c6b4f04698a90a573cd06480d05bd0c20b2aa\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-arabertv02\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1f7c10cecf08743620c7e224e2f3c6b072e45aee1e88fa324837fd199cf24f21.e7b697f3572c7ddd6984e105b6c6cacc07a625d1195f9be544d26d3ad7d0e442\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "Y_MvIk1murf4",
        "outputId": "d0bdcc97-6729-4e03-9569-c6530338f01c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 40845\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 2552\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2552' max='2552' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2552/2552 33:21, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.204800</td>\n",
              "      <td>0.190714</td>\n",
              "      <td>0.856692</td>\n",
              "      <td>0.929977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.133500</td>\n",
              "      <td>0.207887</td>\n",
              "      <td>0.872910</td>\n",
              "      <td>0.934287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 10211\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train/checkpoint-1276\n",
            "Configuration saved in ./train/checkpoint-1276/config.json\n",
            "Model weights saved in ./train/checkpoint-1276/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10211\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train/checkpoint-2552\n",
            "Configuration saved in ./train/checkpoint-2552/config.json\n",
            "Model weights saved in ./train/checkpoint-2552/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train/checkpoint-2552 (score: 0.8729101252510953).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2552, training_loss=0.17948380121990432, metrics={'train_runtime': 2002.5714, 'train_samples_per_second': 40.793, 'train_steps_per_second': 1.274, 'total_flos': 5372530417159680.0, 'train_loss': 0.17948380121990432, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inv_label_map = inv_label_map = { v:k for k, v in label_map.items()}\n",
        "print(inv_label_map)\n",
        "trainer.model.config.label2id = label_map\n",
        "trainer.model.config.id2label = inv_label_map\n",
        "trainer.save_model(\"output_dir\")\n",
        "train_dataset.tokenizer.save_pretrained(\"output_dir\")"
      ],
      "metadata": {
        "id": "ixt07iGQxnzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c67907-f170-491c-f8f9-8e0201a81fb2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to output_dir\n",
            "Configuration saved in output_dir/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'NEG', 1: 'POS'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in output_dir/pytorch_model.bin\n",
            "tokenizer config file saved in output_dir/tokenizer_config.json\n",
            "Special tokens file saved in output_dir/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('output_dir/tokenizer_config.json',\n",
              " 'output_dir/special_tokens_map.json',\n",
              " 'output_dir/vocab.txt',\n",
              " 'output_dir/added_tokens.json',\n",
              " 'output_dir/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp output_dir /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "UPaUtoRsx3En",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fff623-573d-4e4f-8e34-a498d4811a19"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: -r not specified; omitting directory 'output_dir'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Predict Using The Saved Model**"
      ],
      "metadata": {
        "id": "Cdy8x_MU8x2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "gYhVAdMcx-Bt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"sentiment-analysis\", model=\"output_dir\", device=0, return_all_scores=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvUTmdomyBis",
        "outputId": "bb874d3f-2473-48d5-e532-64bdaeadd51d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file output_dir/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading configuration file output_dir/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file output_dir/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at output_dir.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "Didn't find file output_dir/added_tokens.json. We won't load it.\n",
            "loading file output_dir/vocab.txt\n",
            "loading file output_dir/tokenizer.json\n",
            "loading file None\n",
            "loading file output_dir/special_tokens_map.json\n",
            "loading file output_dir/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"Some Text\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wn1ZMQbyHyH",
        "outputId": "52dde8a9-70e6-4be7-8692-51e9593bca64"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'NEG', 'score': 0.23854881525039673},\n",
              "  {'label': 'POS', 'score': 0.7614511847496033}]]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. K-fold & Ensemble all the cross validation models**"
      ],
      "metadata": {
        "id": "rOufXzCl9Eab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do kfold on the training. Check the perfomance on the test set\n",
        "kfold_dataset = selected_dataset.train\n",
        "# do kfold on all the dataset. Here we will not have any dataset to checl final performance on (this is used mainly in competitions)\n",
        "# kfold_dataset = pd.concat([selected_dataset.train,selected_dataset.test])\n",
        "kfold_dataset.reset_index(inplace=True,drop=True)"
      ],
      "metadata": {
        "id": "_wQ7et7-yUPV"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_label_map = { v:k for k, v in label_map.items()}"
      ],
      "metadata": {
        "id": "3WU0PdGFyYmG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kf = StratifiedKFold(\n",
        "    n_splits=5,\n",
        "    shuffle=True,\n",
        "    random_state=123\n",
        "  )"
      ],
      "metadata": {
        "id": "1KV6-H_oygNx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results = []\n",
        "fold_best_f1 = 0\n",
        "best_fold = None\n",
        "for fold_num , (train, dev) in enumerate(kf.split(kfold_dataset,kfold_dataset['label'])):\n",
        "  print(\"**************************Starting Fold Num: \", fold_num,\" **************************\")\n",
        "  \n",
        "  train_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][train]),\n",
        "                              list(kfold_dataset[LABEL_COLUMN][train]),\n",
        "                              model_name,\n",
        "                              max_len,\n",
        "                              label_map)\n",
        "  \n",
        "  val_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][dev]),\n",
        "                              list(kfold_dataset[LABEL_COLUMN][dev]),\n",
        "                              model_name,\n",
        "                              max_len,\n",
        "                              label_map)\n",
        "  \n",
        "  training_args = TrainingArguments( \n",
        "    output_dir= f\"./train_{fold_num}\",    \n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False,\n",
        "    per_device_train_batch_size = 64,\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 123\n",
        "  )\n",
        "\n",
        "  set_seed(training_args.seed)\n",
        "\n",
        "  trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "  )\n",
        "  trainer.model.config.label2id = label_map\n",
        "  trainer.model.config.id2label = inv_label_map\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  results = trainer.evaluate()\n",
        "  all_results.append(results)\n",
        "  print(results)\n",
        "\n",
        "  trainer.save_model(f\"./train_{fold_num}/best_model\")\n",
        "  val_dataset.tokenizer.save_pretrained(f\"./train_{fold_num}/best_model\")\n",
        "\n",
        "  # delete the rest of the checkpoints\n",
        "  !rm -rf f\"./train_{fold_num}/checkpoint-*\" \n",
        "  \n",
        "  if results['eval_macro_f1'] > fold_best_f1:\n",
        "    print('**************************New Best Model Found!**************************')\n",
        "    fold_best_f1 = results['eval_macro_f1']\n",
        "    best_fold = fold_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KAvuBAQBynNN",
        "outputId": "efce10c1-01de-441f-8ac9-cb7ab870ed71"
      },
      "execution_count": 78,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**************************Starting Fold Num:  0  **************************\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1109ac490c1eb90f74960e17c00032f27ea3c4be159567d7ed5d2b5908f9855c.01294502d101541d98086466d32c6b4f04698a90a573cd06480d05bd0c20b2aa\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-arabertv02\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1f7c10cecf08743620c7e224e2f3c6b072e45aee1e88fa324837fd199cf24f21.e7b697f3572c7ddd6984e105b6c6cacc07a625d1195f9be544d26d3ad7d0e442\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 32676\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 510\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [510/510 25:18, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.206857</td>\n",
              "      <td>0.836600</td>\n",
              "      <td>0.920798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>0.206530</td>\n",
              "      <td>0.847837</td>\n",
              "      <td>0.924226</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_0/checkpoint-255\n",
            "Configuration saved in ./train_0/checkpoint-255/config.json\n",
            "Model weights saved in ./train_0/checkpoint-255/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_0/checkpoint-510\n",
            "Configuration saved in ./train_0/checkpoint-510/config.json\n",
            "Model weights saved in ./train_0/checkpoint-510/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_0/checkpoint-510 (score: 0.8478373471865663).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 01:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./train_0/best_model\n",
            "Configuration saved in ./train_0/best_model/config.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.20653036236763, 'eval_macro_f1': 0.8478373471865663, 'eval_accuracy': 0.9242257314236749, 'eval_runtime': 67.9659, 'eval_samples_per_second': 120.193, 'eval_steps_per_second': 0.942, 'epoch': 2.0}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in ./train_0/best_model/pytorch_model.bin\n",
            "tokenizer config file saved in ./train_0/best_model/tokenizer_config.json\n",
            "Special tokens file saved in ./train_0/best_model/special_tokens_map.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**************************New Best Model Found!**************************\n",
            "**************************Starting Fold Num:  1  **************************\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1109ac490c1eb90f74960e17c00032f27ea3c4be159567d7ed5d2b5908f9855c.01294502d101541d98086466d32c6b4f04698a90a573cd06480d05bd0c20b2aa\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-arabertv02\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1f7c10cecf08743620c7e224e2f3c6b072e45aee1e88fa324837fd199cf24f21.e7b697f3572c7ddd6984e105b6c6cacc07a625d1195f9be544d26d3ad7d0e442\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 32676\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 510\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='95' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 95/510 04:10 < 18:38, 0.37 it/s, Epoch 0.37/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [510/510 25:16, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.196972</td>\n",
              "      <td>0.851845</td>\n",
              "      <td>0.927408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.208300</td>\n",
              "      <td>0.193537</td>\n",
              "      <td>0.859737</td>\n",
              "      <td>0.930346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_1/checkpoint-255\n",
            "Configuration saved in ./train_1/checkpoint-255/config.json\n",
            "Model weights saved in ./train_1/checkpoint-255/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_1/checkpoint-510\n",
            "Configuration saved in ./train_1/checkpoint-510/config.json\n",
            "Model weights saved in ./train_1/checkpoint-510/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_1/checkpoint-510 (score: 0.85973720648017).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 01:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./train_1/best_model\n",
            "Configuration saved in ./train_1/best_model/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.19353707134723663, 'eval_macro_f1': 0.85973720648017, 'eval_accuracy': 0.9303464316317787, 'eval_runtime': 68.0708, 'eval_samples_per_second': 120.007, 'eval_steps_per_second': 0.94, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in ./train_1/best_model/pytorch_model.bin\n",
            "tokenizer config file saved in ./train_1/best_model/tokenizer_config.json\n",
            "Special tokens file saved in ./train_1/best_model/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************New Best Model Found!**************************\n",
            "**************************Starting Fold Num:  2  **************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1109ac490c1eb90f74960e17c00032f27ea3c4be159567d7ed5d2b5908f9855c.01294502d101541d98086466d32c6b4f04698a90a573cd06480d05bd0c20b2aa\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-arabertv02\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1f7c10cecf08743620c7e224e2f3c6b072e45aee1e88fa324837fd199cf24f21.e7b697f3572c7ddd6984e105b6c6cacc07a625d1195f9be544d26d3ad7d0e442\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 32676\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [510/510 25:17, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.198331</td>\n",
              "      <td>0.853152</td>\n",
              "      <td>0.923002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.209300</td>\n",
              "      <td>0.194694</td>\n",
              "      <td>0.855017</td>\n",
              "      <td>0.927776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_2/checkpoint-255\n",
            "Configuration saved in ./train_2/checkpoint-255/config.json\n",
            "Model weights saved in ./train_2/checkpoint-255/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_2/checkpoint-510\n",
            "Configuration saved in ./train_2/checkpoint-510/config.json\n",
            "Model weights saved in ./train_2/checkpoint-510/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_2/checkpoint-510 (score: 0.8550166301719762).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 01:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./train_2/best_model\n",
            "Configuration saved in ./train_2/best_model/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.19469380378723145, 'eval_macro_f1': 0.8550166301719762, 'eval_accuracy': 0.927775737544375, 'eval_runtime': 68.0301, 'eval_samples_per_second': 120.079, 'eval_steps_per_second': 0.941, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in ./train_2/best_model/pytorch_model.bin\n",
            "tokenizer config file saved in ./train_2/best_model/tokenizer_config.json\n",
            "Special tokens file saved in ./train_2/best_model/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************Starting Fold Num:  3  **************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1109ac490c1eb90f74960e17c00032f27ea3c4be159567d7ed5d2b5908f9855c.01294502d101541d98086466d32c6b4f04698a90a573cd06480d05bd0c20b2aa\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-arabertv02\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1f7c10cecf08743620c7e224e2f3c6b072e45aee1e88fa324837fd199cf24f21.e7b697f3572c7ddd6984e105b6c6cacc07a625d1195f9be544d26d3ad7d0e442\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 32676\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [510/510 25:17, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.192374</td>\n",
              "      <td>0.851629</td>\n",
              "      <td>0.928265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.212000</td>\n",
              "      <td>0.186066</td>\n",
              "      <td>0.867239</td>\n",
              "      <td>0.932672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_3/checkpoint-255\n",
            "Configuration saved in ./train_3/checkpoint-255/config.json\n",
            "Model weights saved in ./train_3/checkpoint-255/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_3/checkpoint-510\n",
            "Configuration saved in ./train_3/checkpoint-510/config.json\n",
            "Model weights saved in ./train_3/checkpoint-510/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_3/checkpoint-510 (score: 0.8672387745337674).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 01:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./train_3/best_model\n",
            "Configuration saved in ./train_3/best_model/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.18606628477573395, 'eval_macro_f1': 0.8672387745337674, 'eval_accuracy': 0.9326722977108581, 'eval_runtime': 68.0443, 'eval_samples_per_second': 120.054, 'eval_steps_per_second': 0.941, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in ./train_3/best_model/pytorch_model.bin\n",
            "tokenizer config file saved in ./train_3/best_model/tokenizer_config.json\n",
            "Special tokens file saved in ./train_3/best_model/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************New Best Model Found!**************************\n",
            "**************************Starting Fold Num:  4  **************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/dbef00ddc9b64a66ba8057785b166b744cef2a41be973446ad897a56ad317019.aa4ad61e3b0a52c7bcf5410af86ef01a27cf1147665acd6bfba80731d053f78a\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46fef3ab20b06df535befe0412ab892f9baec0a9f8e64d75a0142a67ce366959.c7c33ce0611a0a55c52a9ba4c03992b47db6e8b9862113443132ed9af7185a19\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/7f74425f6809cddb05d5de7967a5af4e325b04245017a7b1917fe7d5cfb06988.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/582bc76b2b3acaaf545878170de8fbf8d6d1f65bd0180769ff4ed901cd60d3c4.9badb1b6af7f7e89d855c8fbc79dd73ef57ac1c9e573a43862ddaeb2c798a290\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1109ac490c1eb90f74960e17c00032f27ea3c4be159567d7ed5d2b5908f9855c.01294502d101541d98086466d32c6b4f04698a90a573cd06480d05bd0c20b2aa\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-arabertv02\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/aubmindlab/bert-base-arabertv02-twitter/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1f7c10cecf08743620c7e224e2f3c6b072e45aee1e88fa324837fd199cf24f21.e7b697f3572c7ddd6984e105b6c6cacc07a625d1195f9be544d26d3ad7d0e442\n",
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 32676\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [510/510 25:18, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.193069</td>\n",
              "      <td>0.854595</td>\n",
              "      <td>0.929367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.207700</td>\n",
              "      <td>0.190931</td>\n",
              "      <td>0.862639</td>\n",
              "      <td>0.930836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_4/checkpoint-255\n",
            "Configuration saved in ./train_4/checkpoint-255/config.json\n",
            "Model weights saved in ./train_4/checkpoint-255/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to ./train_4/checkpoint-510\n",
            "Configuration saved in ./train_4/checkpoint-510/config.json\n",
            "Model weights saved in ./train_4/checkpoint-510/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./train_4/checkpoint-510 (score: 0.8626385653413846).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8169\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 01:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./train_4/best_model\n",
            "Configuration saved in ./train_4/best_model/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.1909308135509491, 'eval_macro_f1': 0.8626385653413846, 'eval_accuracy': 0.930836087648427, 'eval_runtime': 67.9565, 'eval_samples_per_second': 120.209, 'eval_steps_per_second': 0.942, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in ./train_4/best_model/pytorch_model.bin\n",
            "tokenizer config file saved in ./train_4/best_model/tokenizer_config.json\n",
            "Special tokens file saved in ./train_4/best_model/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAnvIYvr90gm",
        "outputId": "cbccece2-364e-4617-85e6-5e6cc4ee2979"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'epoch': 2.0,\n",
              "  'eval_accuracy': 0.9242257314236749,\n",
              "  'eval_loss': 0.20653036236763,\n",
              "  'eval_macro_f1': 0.8478373471865663,\n",
              "  'eval_runtime': 67.9659,\n",
              "  'eval_samples_per_second': 120.193,\n",
              "  'eval_steps_per_second': 0.942},\n",
              " {'epoch': 2.0,\n",
              "  'eval_accuracy': 0.9303464316317787,\n",
              "  'eval_loss': 0.19353707134723663,\n",
              "  'eval_macro_f1': 0.85973720648017,\n",
              "  'eval_runtime': 68.0708,\n",
              "  'eval_samples_per_second': 120.007,\n",
              "  'eval_steps_per_second': 0.94},\n",
              " {'epoch': 2.0,\n",
              "  'eval_accuracy': 0.927775737544375,\n",
              "  'eval_loss': 0.19469380378723145,\n",
              "  'eval_macro_f1': 0.8550166301719762,\n",
              "  'eval_runtime': 68.0301,\n",
              "  'eval_samples_per_second': 120.079,\n",
              "  'eval_steps_per_second': 0.941},\n",
              " {'epoch': 2.0,\n",
              "  'eval_accuracy': 0.9326722977108581,\n",
              "  'eval_loss': 0.18606628477573395,\n",
              "  'eval_macro_f1': 0.8672387745337674,\n",
              "  'eval_runtime': 68.0443,\n",
              "  'eval_samples_per_second': 120.054,\n",
              "  'eval_steps_per_second': 0.941},\n",
              " {'epoch': 2.0,\n",
              "  'eval_accuracy': 0.930836087648427,\n",
              "  'eval_loss': 0.1909308135509491,\n",
              "  'eval_macro_f1': 0.8626385653413846,\n",
              "  'eval_runtime': 67.9565,\n",
              "  'eval_samples_per_second': 120.209,\n",
              "  'eval_steps_per_second': 0.942}]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "mean([x['eval_macro_f1'] for x in all_results])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1FaBGml98tc",
        "outputId": "3d512bad-91e5-42fa-9768-79262d233f2d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8584937047427729"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import more_itertools"
      ],
      "metadata": {
        "id": "OuErnHPK-LTF"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_label_map = { v:k for k, v in label_map.items()}"
      ],
      "metadata": {
        "id": "AS-isgjU-PGn"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = selected_dataset.test[DATA_COLUMN]"
      ],
      "metadata": {
        "id": "WZPy-5Rm-VCx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_df = pd.DataFrame([])\n",
        "for i in range(0,5):\n",
        "  pipe = pipeline(\"sentiment-analysis\", model=f\"train_{i}/best_model\", device=0, return_all_scores =True, max_length=max_len, truncation=True)\n",
        "  preds = []\n",
        "  for s in tqdm(more_itertools.chunked(list(pred_df), 32)): # batching for faster inference\n",
        "    preds.extend(pipe(s))\n",
        "  cross_val_df[f'model_{i}'] = preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c0b7c50d30564cffa1d88e417e6f81e1",
            "1f17d138f5e04cfaa401d75d2a28c63c",
            "3efa519a89cc4a4ab50977e430a8ad05",
            "0d42ef2901bd4c4db253e1c1afa1148c",
            "247e86aa79f84332999a5af37c35586a",
            "b43275755ec843aa859a20957e58085c",
            "eedf78bd08f843c48d96968e8c2e131f",
            "fe2fb853ab8c4e9d990e477c9c0a73c0",
            "808409806ffc4fadb057e8cfd726ffaa",
            "f5ce510a65b54645ae96f2c4c2a3697d",
            "ddbff536c0224cd08f67302508a2e888",
            "c40b3c7c2ca94ce189776e3c79bd4346",
            "37e6ed1bfc2841d583ac1804f5a66bc1",
            "fc06940e55284e1ea3e8cb10e2c1921d",
            "1164dabbe8e6469cb8413dc8f980c471",
            "8568faac56a942098b353b73305a9737",
            "18c9cff572c946cfb2b75f7ad2527c1f",
            "0b2543d3cbd7463d9b453ddd39a92e33",
            "81d757c6e8c74210afd30f70300cfe5e",
            "1077803fa1704a4bb01828e4a6c0760b",
            "835305276fd54a6bb2d9fbca9fdd1aa7",
            "3e24cf380c3b44b780036712ef69fb3e",
            "9d38353721c443f2b66c2574ea8b0cae",
            "1fd815c51acc4ceeb139d6edaaa796dc",
            "989deb7602974dffae354368dd318fbb",
            "8e4dd91b134e476d825d4ca6d282acab",
            "60ec7568744346a4b44c64c572e1650a",
            "27b9e4c93b60440ba717875698235a27",
            "2e8ba307865a46e3a7488aa7027785b6",
            "2fd3bee219a64573acbcac006fc1c39c",
            "92b2e795fcc94259bdcf57630db3f194",
            "d3748643c28f4415b14b180c2af2bfa1",
            "b0d35bb9c6f14599b55c0cb49ced3a0f",
            "4a431257ae1a47cd9a05e9e985132d38",
            "75064b69e349439286e969d8eb62720e",
            "0cacb1541f344269af578a82c1f3fd97",
            "431469f32f664e7ba18e6d584b0b29ec",
            "7dcfc6fe997148149742a17027e1fa16",
            "facdfd8baf07418aa2403e21168e3fb7",
            "d1f984b8dbb748f58f0c7ad7af6e6f66",
            "3f837d43d2e046e693a0144d52b43c5a",
            "0d68817a9201413d9a0f66be0b94c20a",
            "abad8243935d48c2a321e2d47e77c6b1",
            "243cc5e7073448dbbb3bef448f8c79d6",
            "1889fdc2e4e14df6ba18a7bcdb43875d",
            "5eb20352e905428583013a16d794cf77",
            "76dc38e571344f58a410d7a255f101e4",
            "df29f51786f946c5b92d78f08f04b224",
            "f1e650a85340472f8e6e14d30f83a92e",
            "04be8b29332343d5b72302eaf0342dd3",
            "144bb19fd96d492cb7db32d09c882430",
            "5003f2c4397e43ca89a889a7b0891525",
            "e721e7dd6fa44c82bbe167409b3636ba",
            "0de3eb4866da474d80507af29f63fbcf",
            "7077374dfa494347874ce61f313100e2"
          ]
        },
        "id": "xQK8uMuk-Y1x",
        "outputId": "0150eac3-33f5-4bba-c126-c533768dc1cd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file train_0/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading configuration file train_0/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file train_0/best_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at train_0/best_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "Didn't find file train_0/best_model/added_tokens.json. We won't load it.\n",
            "loading file train_0/best_model/vocab.txt\n",
            "loading file train_0/best_model/tokenizer.json\n",
            "loading file None\n",
            "loading file train_0/best_model/special_tokens_map.json\n",
            "loading file train_0/best_model/tokenizer_config.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0b7c50d30564cffa1d88e417e6f81e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py:910: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  UserWarning,\n",
            "loading configuration file train_1/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading configuration file train_1/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file train_1/best_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at train_1/best_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "Didn't find file train_1/best_model/added_tokens.json. We won't load it.\n",
            "loading file train_1/best_model/vocab.txt\n",
            "loading file train_1/best_model/tokenizer.json\n",
            "loading file None\n",
            "loading file train_1/best_model/special_tokens_map.json\n",
            "loading file train_1/best_model/tokenizer_config.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c40b3c7c2ca94ce189776e3c79bd4346"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file train_2/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading configuration file train_2/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file train_2/best_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at train_2/best_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "Didn't find file train_2/best_model/added_tokens.json. We won't load it.\n",
            "loading file train_2/best_model/vocab.txt\n",
            "loading file train_2/best_model/tokenizer.json\n",
            "loading file None\n",
            "loading file train_2/best_model/special_tokens_map.json\n",
            "loading file train_2/best_model/tokenizer_config.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d38353721c443f2b66c2574ea8b0cae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file train_3/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading configuration file train_3/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file train_3/best_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at train_3/best_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "Didn't find file train_3/best_model/added_tokens.json. We won't load it.\n",
            "loading file train_3/best_model/vocab.txt\n",
            "loading file train_3/best_model/tokenizer.json\n",
            "loading file None\n",
            "loading file train_3/best_model/special_tokens_map.json\n",
            "loading file train_3/best_model/tokenizer_config.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a431257ae1a47cd9a05e9e985132d38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file train_4/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading configuration file train_4/best_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"aubmindlab/bert-base-arabertv02-twitter\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"POS\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file train_4/best_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at train_4/best_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "Didn't find file train_4/best_model/added_tokens.json. We won't load it.\n",
            "loading file train_4/best_model/vocab.txt\n",
            "loading file train_4/best_model/tokenizer.json\n",
            "loading file None\n",
            "loading file train_4/best_model/special_tokens_map.json\n",
            "loading file train_4/best_model/tokenizer_config.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1889fdc2e4e14df6ba18a7bcdb43875d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "final_labels = []\n",
        "final_scores = []\n",
        "for id, row in cross_val_df.iterrows():\n",
        "  total_score = defaultdict(lambda: 0)  \n",
        "  for pred in row:\n",
        "    for cls in pred:\n",
        "      total_score[cls['label']] += cls['score']\n",
        "\n",
        "  avg_score = { k: v/ 5 for k, v in total_score.items()}\n",
        "\n",
        "  final_labels.append(max(avg_score, key=avg_score.get))\n",
        "  final_scores.append(avg_score[max(avg_score, key=avg_score.get)])"
      ],
      "metadata": {
        "id": "vRl2GyhJCMzy"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_df['preds'] = final_labels \n",
        "cross_val_df['sentiment_score'] = final_scores "
      ],
      "metadata": {
        "id": "uQelD1PlCSGy"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_df['preds'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQs9kHYsCUKp",
        "outputId": "fac8f55f-1673-4226-d1ba-b7800c530168"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POS    8881\n",
              "NEG    1330\n",
              "Name: preds, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(selected_dataset.test[LABEL_COLUMN],cross_val_df['preds']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnMF8HtfCZmC",
        "outputId": "81d0e446-d9e4-46e5-937e-3d0db32f4c43"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NEG       0.85      0.68      0.75      1670\n",
            "         POS       0.94      0.98      0.96      8541\n",
            "\n",
            "    accuracy                           0.93     10211\n",
            "   macro avg       0.90      0.83      0.86     10211\n",
            "weighted avg       0.92      0.93      0.92     10211\n",
            "\n"
          ]
        }
      ]
    }
  ]
}